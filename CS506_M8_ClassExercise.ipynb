{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Computer Vision with Convolutional Neural Networks (CNNs)\n",
        "### A Hands-On Keras Exercise (using CIFAR-10 Dataset)\n",
        "\n",
        "**Objective:** This assignment will introduce you to Convolutional Neural Networks (CNNs) for image classification using the CIFAR-10 dataset. You will learn to load and preprocess color image datasets, build and train CNNs, apply regularization techniques (Batch Normalization, Dropout), experiment with optimizers, and evaluate model performance.\n",
        "\n",
        "**Estimated Time:** 30-45 Minutes\n",
        "\n",
        "**Materials:**\n",
        "\n",
        "* Jupyter Notebook environment (or Google Colab)\n",
        "* Python 3 installed with `tensorflow` (which includes Keras), `scikit-learn`, `matplotlib`, and `numpy`."
      ],
      "metadata": {
        "id": "SlLZlavCVx02"
      },
      "id": "SlLZlavCVx02"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "M__OZhH8Vx03"
      },
      "id": "M__OZhH8Vx03"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 1: Setting the Stage - Libraries and Data Loading\n",
        "\n",
        "**1.1 Load Essential Python Libraries**\n",
        "\n",
        "* **Task:** Begin by importing all the necessary libraries for this assignment. Pay attention to the new layers specifically for CNNs.\n"
      ],
      "metadata": {
        "id": "qwlXyZBKVx04"
      },
      "id": "qwlXyZBKVx04"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Keras for building neural networks\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical # For one-hot encoding labels\n",
        "\n",
        "# Specific CNN layers\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# Scikit-learn for data splitting and metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "load_libraries"
      },
      "outputs": [],
      "id": "load_libraries",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevant Documentation:**\n",
        "* `Conv2D`: This is the convolutional layer for 2D inputs (like images). It applies a set of learnable filters to the input, creating feature maps. [Keras Conv2D Documentation](https://keras.io/api/layers/convolution_layers/convolution2d/)\n",
        "    * **Sample Syntax:** `layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3))`\n",
        "* `MaxPooling2D`: This is a pooling layer that reduces the spatial dimensions (height and width) of the input. It helps in reducing computational cost and extracting dominant features. [Keras MaxPooling2D Documentation](https://keras.io/api/layers/pooling_layers/max_pooling2d/)\n",
        "    * **Sample Syntax:** `layers.MaxPooling2D((2, 2))`\n",
        "* `Flatten`: This layer flattens the input from a multi-dimensional shape (e.g., from convolutional layers) into a 1D array. This is necessary before passing the data to fully connected (`Dense`) layers. [Keras Flatten Documentation](https://keras.io/api/layers/reshaping_layers/flatten/)\n",
        "    * **Sample Syntax:** `layers.Flatten()`\n",
        "\n",
        "**1.2 Load a Computer Vision Dataset (CIFAR-10)**\n",
        "\n",
        "* **Task:** Load the CIFAR-10 dataset, which consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class.\n",
        "* **Instructions:**\n",
        "    * Use `keras.datasets.cifar10.load_data()` to load the dataset. It comes pre-split into training and testing sets.\n",
        "    * Print the shapes of `X_train`, `y_train`, `X_test`, and `y_test` to understand their dimensions."
      ],
      "metadata": {
        "id": "6diByKlXVx05"
      },
      "id": "6diByKlXVx05"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset using variable names  X_train_full, y_train_full, X_test, y_test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f\"X_train_full shape: {X_train_full.shape}\") # (num_samples, height, width, channels)\n",
        "print(f\"y_train_full shape: {y_train_full.shape}\") # (num_samples, 1)\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "num_classes = len(np.unique(y_train_full))\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Define class names for CIFAR-10 for better interpretation of results\n",
        "cifar10_class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                       'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "load_cifar10"
      },
      "outputs": [],
      "id": "load_cifar10",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 Data Exploration: Visualize Sample Images**\n",
        "\n",
        "* **Task:** Display a few sample images from the training set to get a feel for the data.\n",
        "* **Instructions:**\n",
        "    * Use `matplotlib.pyplot` to plot 5-10 images.\n",
        "    * Display the corresponding label for each image using the `cifar10_class_names`."
      ],
      "metadata": {
        "id": "MNv--8QcVx05"
      },
      "id": "MNv--8QcVx05"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(X_train_full[i]) # CIFAR-10 images are color, no cmap needed\n",
        "    plt.title(f\"Label: {cifar10_class_names[y_train_full[i][0]]}\") # y_train_full is 2D array\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "visualize_samples"
      },
      "outputs": [],
      "id": "visualize_samples",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "VVn7Df2AVx06"
      },
      "id": "VVn7Df2AVx06"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 2: Data Preprocessing for CNNs\n",
        "\n",
        "**2.1 Reshape Data for CNN Input (No Reshaping Needed for CIFAR-10)**\n",
        "\n",
        "* **Task:** CIFAR-10 images are already in the `(batch_size, height, width, channels)` format, with 3 channels for RGB. So, no explicit reshaping is needed here, but we will define `input_shape`.\n",
        "* **Instructions:** Define the `input_shape` based on the loaded data dimensions."
      ],
      "metadata": {
        "id": "bQXjkkVwVx06"
      },
      "id": "bQXjkkVwVx06"
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows, img_cols, channels = X_train_full.shape[1], X_train_full.shape[2], X_train_full.shape[3]\n",
        "input_shape = (img_rows, img_cols, channels) # 3 for RGB channels\n",
        "\n",
        "print(f\"Input shape for CNN: {input_shape}\")\n",
        "print(f\"X_train_full shape (already correct): {X_train_full.shape}\")\n",
        "print(f\"X_test shape (already correct): {X_test.shape}\")"
      ],
      "metadata": {
        "id": "reshape_data"
      },
      "outputs": [],
      "id": "reshape_data",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevant Documentation:**\n",
        "The channel dimension is crucial for CNNs, especially for color images. It represents the different color channels (e.g., Red, Green, Blue for RGB images). CNNs process information across these channels to identify features based on color variations, unlike grayscale images which have only one channel. For CIFAR-10, images are 32x32 pixels with 3 color channels, so the input shape is (32, 32, 3).\n",
        "\n",
        "**2.2 Normalize Pixel Values**\n",
        "\n",
        "* **Task:** Scale the pixel values from the 0-255 range to a 0-1 range. This helps neural networks train more effectively.\n",
        "* **Instructions:** Convert the data type to float and divide by 255."
      ],
      "metadata": {
        "id": "3Uv8jmeIVx06"
      },
      "id": "3Uv8jmeIVx06"
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the dataset using variable names X_train_normalized,X_test_normalized\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Min pixel value (train): {np.min(X_train_normalized)}\")\n",
        "print(f\"Max pixel value (train): {np.max(X_train_normalized)}\")"
      ],
      "metadata": {
        "id": "normalize_pixels"
      },
      "outputs": [],
      "id": "normalize_pixels",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevant Documentation:**\n",
        "Normalizing pixel values (scaling them to a 0-1 range) is beneficial for neural networks because:\n",
        "* **Faster Convergence:** It helps gradient descent-based optimizers converge more quickly as all features are on a similar scale.\n",
        "* **Improved Performance:** Prevents larger input values from dominating the learning process, leading to more stable and potentially better model performance.\n",
        "* **Activation Function Range:** Many activation functions (like sigmoid or tanh) work best with inputs close to zero. Normalization ensures inputs fall within these optimal ranges.\n",
        "    * **Sample Syntax:** `X_data = X_data.astype('float32') / 255`\n",
        "\n",
        "**2.3 One-Hot Encode Labels**\n",
        "\n",
        "* **Task:** Convert integer labels (0-9) into a one-hot encoded format (e.g., `5` becomes `[0,0,0,0,0,1,0,0,0,0]`). This is necessary for `categorical_crossentropy` loss.\n",
        "* **Instructions:** Use `tf.keras.utils.to_categorical`."
      ],
      "metadata": {
        "id": "3B80D7eEVx06"
      },
      "id": "3B80D7eEVx06"
    },
    {
      "cell_type": "code",
      "source": [
        "# try using one hot encoding using variable names y_train_one_hot,y_test_one_hot\n",
        "\n",
        "print(f\"Original label for first sample: {y_train_full[0][0]}\") # y_train_full is 2D array\n",
        "print(f\"One-hot encoded label for first sample: {y_train_one_hot[0]}\")\n",
        "print(f\"y_train_one_hot shape: {y_train_one_hot.shape}\")"
      ],
      "metadata": {
        "id": "one_hot_encode"
      },
      "outputs": [],
      "id": "one_hot_encode",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevant Documentation:**\n",
        "* `sparse_categorical_crossentropy`: This loss function is used when your labels are integers (e.g., 0, 1, 2 for classes). It performs an implicit one-hot encoding internally.\n",
        "* `categorical_crossentropy`: This loss function is used when your labels are already in one-hot encoded format (e.g., `[0,0,1,0]` for class 2). You must explicitly convert your integer labels to one-hot encoding using `to_categorical`.\n",
        "\n",
        "Choose `categorical_crossentropy` when your output layer uses `softmax` activation and your labels are one-hot encoded. If your labels are integers and your output is `softmax`, `sparse_categorical_crossentropy` is more convenient. [Keras Losses Documentation](https://keras.io/api/losses/)\n",
        "    * **Sample Syntax:** `y_one_hot = to_categorical(y_integer_labels, num_classes=10)`\n",
        "\n",
        "**2.4 Data Splitting (Train, Validation, Test)**\n",
        "\n",
        "* **Task:** Split your training data into a smaller training set and a validation set. The test set is already separate.\n",
        "* **Instructions:** Use `train_test_split` on the *normalized and one-hot encoded* training data (`X_train_normalized`, `y_train_one_hot`) for your training and validation sets. Aim for an 80/20 or 90/10 split."
      ],
      "metadata": {
        "id": "TUFS7W7lVx07"
      },
      "id": "TUFS7W7lVx07"
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data set. you can use variable names X_train, X_val, y_train, y_val\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
        "print(f\"X_test shape: {X_test_normalized.shape}, y_test shape: {y_test_one_hot.shape}\")"
      ],
      "metadata": {
        "id": "KQg3Mc4kVx07"
      },
      "id": "KQg3Mc4kVx07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevant Documentation:**\n",
        "Having separate training, validation, and test sets is fundamental for robust model evaluation:\n",
        "* **Training Set:** Used to train the model and adjust its weights.\n",
        "* **Validation Set:** Used to tune hyperparameters (like learning rate, number of layers, dropout rates) and monitor for overfitting during training. It provides an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters.\n",
        "* **Test Set:** Used for a final, unbiased evaluation of the model's performance after all hyperparameter tuning is complete. This set should *never* be used during training or hyperparameter tuning to ensure the model generalizes well to new, unseen data.\n",
        "\n",
        "If you only use a train-test split and tune hyperparameters based on the test set, you risk overfitting to the test set, leading to an overly optimistic estimate of your model's real-world performance.\n",
        "    * **Sample Syntax:** `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)`\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Ppgmo8I8Vx07"
      },
      "id": "Ppgmo8I8Vx07"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3: Building and Training Your First CNN Model\n",
        "\n",
        "**3.1 Create a Simple CNN Model**\n",
        "\n",
        "* **Task:** Construct a basic CNN model. This will involve `Conv2D`, `MaxPooling2D`, `Flatten`, and `Dense` layers.\n",
        "* **Instructions:**\n",
        "    * Define a `Sequential` model.\n",
        "    * Add a `Conv2D` layer (e.g., 32 filters, (3,3) kernel, 'relu' activation, `input_shape` for the first layer).\n",
        "    * Add a `MaxPooling2D` layer (e.g., (2,2) pool size).\n",
        "    * Add another `Conv2D` layer and `MaxPooling2D` layer (optional, but good for deeper features).\n",
        "    * Add a `Flatten` layer to convert the 2D feature maps into a 1D vector.\n",
        "    * Add one or more `Dense` layers for classification (e.g., 128 neurons, 'relu' activation).\n",
        "    * Add the final `Dense` output layer with `num_classes` neurons and `softmax` activation.\n",
        "    * Print `model.summary()`."
      ],
      "metadata": {
        "id": "gCatMsT6Vx07"
      },
      "id": "gCatMsT6Vx07"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create network model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "create_simple_cnn"
      },
      "outputs": [],
      "id": "create_simple_cnn",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevant Documentation:**\n",
        "* **`Conv2D` layers:** These layers apply convolutional filters to the input image. Each filter learns to detect specific features (e.g., edges, textures, patterns). By sliding these filters across the image, they create feature maps that highlight where these features are present. This process allows the network to learn hierarchical representations of the image.\n",
        "* **`MaxPooling2D` layers:** These layers perform downsampling by taking the maximum value within a specified window (pool size). This reduces the spatial dimensions of the feature maps, which helps in:\n",
        "    * Reducing the number of parameters and computational complexity.\n",
        "    * Making the model more robust to small shifts or distortions in the input image (translational invariance).\n",
        "These layers work together to progressively extract more complex and abstract features from the raw pixel data.\n",
        "    * **Sample Syntax:**\n",
        "        ```python\n",
        "        model = Sequential([\n",
        "            Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "            MaxPooling2D((2, 2))\n",
        "        ])\n",
        "        ```\n",
        "\n",
        "**3.2 Compile the Model**\n",
        "\n",
        "* **Task:** Configure the learning process by specifying the optimizer, loss function, and metrics.\n",
        "* **Instructions:**\n",
        "    * Use `model.compile()`.\n",
        "    * For one-hot encoded labels, use `loss='categorical_crossentropy'`.\n",
        "    * Start with the `Adam` optimizer.\n",
        "    * Include `metrics=['accuracy']`."
      ],
      "metadata": {
        "id": "7qRERgXXVx07"
      },
      "id": "7qRERgXXVx07"
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "compile_simple_cnn"
      },
      "outputs": [],
      "id": "compile_simple_cnn",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevant Documentation:**\n",
        "The **learning rate** is a crucial hyperparameter that determines the step size at each iteration while moving toward a minimum of a loss function. A learning rate that is too small can lead to slow convergence, while a learning rate that is too large can cause the optimization to overshoot the minimum or even diverge. It significantly impacts how quickly and effectively a model learns.\n",
        "    * **Sample Syntax:** `model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])`\n",
        "\n",
        "**3.3 Train the Model**\n",
        "\n",
        "* **Task:** Train your CNN using the training and validation data.\n",
        "* **Instructions:**\n",
        "    * Use `model.fit()`.\n",
        "    * Pass `X_train`, `y_train` as training data.\n",
        "    * Pass `X_val`, `y_val` as validation data (using `validation_data` argument).\n",
        "    * Set `epochs` (e.g., 10-20, as CNNs can take longer) and `batch_size` (e.g., 32 or 64).\n",
        "    * Store the training history object in a variable (e.g., `history_simple_cnn`)."
      ],
      "metadata": {
        "id": "uVpKbSXYVx07"
      },
      "id": "uVpKbSXYVx07"
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust below code\n",
        "history_simple_cnn = model_simple_cnn.fit(X_train, y_train,\n",
        "                                          epochs=15,\n",
        "                                          batch_size=64,\n",
        "                                          validation_data=(X_val, y_val),\n",
        "                                          verbose=1)"
      ],
      "metadata": {
        "id": "train_simple_cnn"
      },
      "outputs": [],
      "id": "train_simple_cnn",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevant Documentation:**\n",
        "* **Epochs:** An epoch represents one complete pass through the entire training dataset. In each epoch, the model sees every training example once. More epochs generally lead to better learning, but too many can cause overfitting.\n",
        "* **Batch Size:** The batch size defines the number of training examples utilized in one iteration. Smaller batch sizes introduce more noise into the gradient but can help escape local minima. Larger batch sizes provide a more accurate estimate of the gradient but require more memory.\n",
        "\n",
        "**Signs of Overfitting/Underfitting:**\n",
        "* **Underfitting:** If both training and validation loss are high, and both accuracies are low, the model is likely underfitting. It hasn't learned enough from the training data.\n",
        "* **Overfitting:** If training loss continues to decrease and training accuracy continues to increase, but validation loss starts increasing and validation accuracy plateaus or decreases, the model is overfitting. It's memorizing the training data instead of generalizing.\n",
        "    * **Sample Syntax:** `history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))`\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "RV9KePWUVx08"
      },
      "id": "RV9KePWUVx08"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 4: Model Improvement Techniques and Visualization\n",
        "\n",
        "**4.1 Visualize Training History (Simple CNN)**\n",
        "\n",
        "* **Task:** Plot the training and validation loss, and accuracy over epochs for your simple CNN. This is crucial for performance analysis.\n",
        "* **Instructions:**\n",
        "    * Access the `history_simple_cnn.history` dictionary.\n",
        "    * Plot 'accuracy' vs. 'val_accuracy' and 'loss' vs. 'val_loss' using `matplotlib.pyplot`.\n",
        "    * Add titles, labels, and legends."
      ],
      "metadata": {
        "id": "OiXe66peVx08"
      },
      "id": "OiXe66peVx08"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history, title_prefix=\"Model\"):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title(f'{title_prefix} Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title(f'{title_prefix} Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history_simple_cnn, title_prefix=\"Simple CNN\")"
      ],
      "metadata": {
        "id": "plot_simple_cnn_history"
      },
      "outputs": [],
      "id": "plot_simple_cnn_history",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevant Documentation:**\n",
        "Analyzing the training and validation curves is key to diagnosing model performance:\n",
        "* **Overfitting:** If the training accuracy continues to increase while validation accuracy plateaus or decreases, and training loss continues to decrease while validation loss increases, the model is overfitting. It is learning the training data too well, including its noise, and failing to generalize to new data.\n",
        "* **Underfitting:** If both training and validation accuracy are low and both losses are high, the model is underfitting. It is too simple or hasn't been trained long enough to capture the underlying patterns in the data.\n",
        "* **Good Fit:** Ideally, both training and validation curves should converge and remain close to each other, indicating that the model is learning effectively and generalizing well.\n",
        "\n",
        "**4.2 Incorporate Batch Normalization and Dropout**\n",
        "\n",
        "* **Task:** Create a new CNN model that includes `BatchNormalization` and `Dropout` layers. These are crucial for preventing overfitting in deeper networks.\n",
        "* **Instructions:**\n",
        "    * Define a *new* `Sequential` model.\n",
        "    * **Placement Strategy:** A common pattern is `Conv2D` -> `BatchNormalization` -> `Activation` -> `Dropout` -> `MaxPooling2D`.\n",
        "    * Add `BatchNormalization()` after each `Conv2D` layer (before or after activation, common to put before for ReLU).\n",
        "    * Add `Dropout()` layers after `MaxPooling2D` or after `Dense` layers, with a `rate` (e.g., 0.25 for convolutional blocks, 0.5 for dense layers).\n",
        "    * Compile and train this new model. Store its history (`history_improved_cnn`)."
      ],
      "metadata": {
        "id": "ZWmDgUjaVx08"
      },
      "id": "ZWmDgUjaVx08"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new model and use improvement techniques described above.\n",
        "model_improved_cnn = Sequential([\n",
        "\n",
        "\n",
        "\n",
        "])\n",
        "\n",
        "model_improved_cnn.summary()\n",
        "\n",
        "model_improved_cnn.compile(optimizer='adam',\n",
        "                           loss='categorical_crossentropy',\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n--- Training Improved CNN Model ---\")\n",
        "history_improved_cnn = model_improved_cnn.fit(X_train, y_train,\n",
        "                                               epochs=20, # More epochs might be needed\n",
        "                                               batch_size=64,\n",
        "                                               validation_data=(X_val, y_val),\n",
        "                                               verbose=1)\n",
        "\n",
        "plot_training_history(history_improved_cnn, title_prefix=\"Improved CNN (Adam)\")"
      ],
      "metadata": {
        "id": "improved_cnn_model"
      },
      "outputs": [],
      "id": "improved_cnn_model",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevant Documentation:**\n",
        "* **Batch Normalization:** This technique normalizes the activations of the previous layer at each batch, meaning it centers and scales the inputs to the next layer. This helps in:\n",
        "    * **Stabilizing Learning:** Reduces internal covariate shift, allowing each layer to learn more independently.\n",
        "    * **Faster Convergence:** Allows for higher learning rates.\n",
        "    * **Regularization:** Adds a slight regularization effect, reducing the need for other regularization techniques.\n",
        "    [Keras BatchNormalization Documentation](https://keras.io/api/layers/normalization_layers/batch_normalization/)\n",
        "    * **Sample Syntax:** `layers.BatchNormalization()`\n",
        "\n",
        "* **Dropout:** During training, Dropout randomly sets a fraction of input units to 0 at each update step. This prevents neurons from co-adapting too much and forces the network to learn more robust features. It acts as a powerful regularization technique to prevent overfitting.\n",
        "    [Keras Dropout Documentation](https://keras.io/api/layers/regularization_layers/dropout/)\n",
        "    * **Sample Syntax:** `layers.Dropout(0.5)`\n",
        "\n",
        "By adding these layers, you should observe that the gap between training and validation curves narrows, and validation accuracy might improve or remain stable for longer, indicating better generalization and reduced overfitting compared to the simple CNN.\n",
        "\n",
        "**4.3 Experiment with Different Optimizers on Improved Model**\n",
        "\n",
        "* **Task:** Re-train your *improved* model using different optimizers (e.g., `SGD`, `RMSprop`) and compare their performance, especially focusing on convergence speed and final accuracy.\n",
        "* **Instructions:**\n",
        "    * For each optimizer:\n",
        "        * Create a *fresh instance* of `model_improved_cnn` (important to reset weights).\n",
        "        * Compile it with the new optimizer (e.g., `optimizer=SGD(learning_rate=0.01)`).\n",
        "        * Train it for the same number of epochs and batch size.\n",
        "        * Store the history object.\n",
        "    * Plot the validation accuracy/loss for all three optimizers (Adam, SGD, RMSprop) on the *same graph* for comparison."
      ],
      "metadata": {
        "id": "6r2JugjKVx08"
      },
      "id": "6r2JugjKVx08"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_fresh_improved_cnn():\n",
        "    # Helper function to create a new instance of the improved CNN architecture\n",
        "    return Sequential([\n",
        "        # complete the code with your own improved model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ])\n",
        "\n",
        "# Experiment with SGD\n",
        "print(\"\\n--- Training with SGD Optimizer ---\")\n",
        "model_sgd_improved = create_fresh_improved_cnn()\n",
        "model_sgd_improved.compile(optimizer=SGD(learning_rate=0.01),\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "history_sgd_improved = model_sgd_improved.fit(X_train, y_train,\n",
        "                                              epochs=20,\n",
        "                                              batch_size=64,\n",
        "                                              validation_data=(X_val, y_val),\n",
        "                                              verbose=0) # Set verbose to 0 for cleaner output\n",
        "\n",
        "# Experiment with RMSprop\n",
        "print(\"\\n--- Training with RMSprop Optimizer ---\")\n",
        "model_rmsprop_improved = create_fresh_improved_cnn()\n",
        "model_rmsprop_improved.compile(optimizer=RMSprop(learning_rate=0.001),\n",
        "                              loss='categorical_crossentropy',\n",
        "                              metrics=['accuracy'])\n",
        "history_rmsprop_improved = model_rmsprop_improved.fit(X_train, y_train,\n",
        "                                                      epochs=20,\n",
        "                                                      batch_size=64,\n",
        "                                                      validation_data=(X_val, y_val),\n",
        "                                                      verbose=0)\n",
        "\n",
        "# Plotting comparison of Validation Accuracy\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_improved_cnn.history['val_accuracy'], label='Adam')\n",
        "plt.plot(history_sgd_improved.history['val_accuracy'], label='SGD')\n",
        "plt.plot(history_rmsprop_improved.history['val_accuracy'], label='RMSprop')\n",
        "plt.title('Validation Accuracy Comparison (Improved CNN)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plotting comparison of Validation Loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history_improved_cnn.history['val_loss'], label='Adam')\n",
        "plt.plot(history_sgd_improved.history['val_loss'], label='SGD')\n",
        "plt.plot(history_rmsprop_improved.history['val_loss'], label='RMSprop')\n",
        "plt.title('Validation Loss Comparison (Improved CNN)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "optimizer_experiment"
      },
      "outputs": [],
      "id": "optimizer_experiment",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevant Documentation:**\n",
        "Optimizers are algorithms or methods used to change the attributes of your neural network such as weights and learning rate in order to reduce the losses. Different optimizers have different approaches to navigating the loss landscape:\n",
        "* **Adam (Adaptive Moment Estimation):** Combines ideas from RMSprop and momentum. It calculates adaptive learning rates for each parameter. Generally performs well across a wide range of problems and is often a good default choice.\n",
        "* **SGD (Stochastic Gradient Descent):** The simplest optimizer, it updates weights in the direction of the negative gradient of the loss function. Can be slow to converge and prone to oscillations, but with momentum, it can be very effective.\n",
        "    * **Sample Syntax:** `optimizer=SGD(learning_rate=0.01)`\n",
        "* **RMSprop (Root Mean Square Propagation):** Adapts the learning rate for each parameter based on the magnitudes of recent gradients. It's good for recurrent neural networks and can handle non-stationary objectives.\n",
        "    * **Sample Syntax:** `optimizer=RMSprop(learning_rate=0.001)`\n",
        "\n",
        "You might observe differences in:\n",
        "* **Convergence Speed:** How quickly the validation loss decreases and accuracy increases.\n",
        "* **Stability:** How smooth the training curves are (less oscillation).\n",
        "* **Final Performance:** The best validation accuracy achieved.\n",
        "\n",
        "[Keras Optimizers Documentation](https://keras.io/api/optimizers/)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "TUSHzBCZVx09"
      },
      "id": "TUSHzBCZVx09"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 5: Model Evaluation on Test Set\n",
        "\n",
        "**5.1 Evaluate Final Model**\n",
        "\n",
        "* **Task:** Evaluate the performance of your *best-performing* model (from your optimizer experiments in Part 4.3) on the unseen test set.\n",
        "* **Instructions:**\n",
        "    * Choose the model that showed the best validation accuracy (e.g., `model_improved_cnn` if Adam was best).\n",
        "    * Use `model.evaluate()` on `X_test_normalized` and `y_test_one_hot`.\n",
        "    * Print the test loss and test accuracy."
      ],
      "metadata": {
        "id": "l4lXV1YWVx09"
      },
      "id": "l4lXV1YWVx09"
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming model_improved_cnn (trained with Adam) was your best performing model\n",
        "# If SGD or RMSprop was better, use model_sgd_improved or model_rmsprop_improved\n",
        "best_model = model_improved_cnn # Change this if a different optimizer performed better\n",
        "\n",
        "test_loss, test_accuracy = best_model.evaluate(X_test_normalized, y_test_one_hot, verbose=0)\n",
        "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "evaluate_final_model"
      },
      "outputs": [],
      "id": "evaluate_final_model",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevant Documentation:**\n",
        "The test accuracy provides a final, unbiased estimate of your model's performance on unseen data. Comparing it to the validation accuracy helps assess **generalization**:\n",
        "* If test accuracy is significantly lower than validation accuracy, it might indicate that your model overfit the validation set during hyperparameter tuning, or that the validation set was not perfectly representative of the true data distribution.\n",
        "* If test accuracy is similar to validation accuracy, it suggests that your model generalizes well to new data and your validation set was a good proxy for unseen data.\n",
        "\n",
        "**5.2 Make Predictions and Analyze Metrics**\n",
        "\n",
        "* **Task:** Make predictions on the test set and calculate additional classification metrics.\n",
        "* **Instructions:**\n",
        "    * Use `best_model.predict()` on `X_test_normalized` to get probability predictions.\n",
        "    * Convert probabilities to class predictions (e.g., use `np.argmax`).\n",
        "    * Convert `y_test_one_hot` back to integer labels for `sklearn.metrics` functions.\n",
        "    * Calculate and print the `accuracy_score`, `confusion_matrix`, and `classification_report` from `sklearn.metrics`."
      ],
      "metadata": {
        "id": "8AybIpxgVx09"
      },
      "id": "8AybIpxgVx09"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs = best_model.predict(X_test_normalized)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1) # Convert probabilities to class labels\n",
        "y_test_labels = np.argmax(y_test_one_hot, axis=1) # Convert one-hot to integer labels\n",
        "\n",
        "print(\"\\n--- Classification Metrics on Test Set ---\")\n",
        "print(f\"Accuracy Score: {accuracy_score(y_test_labels, y_pred):.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_labels, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_labels, y_pred, target_names=cifar10_class_names))"
      ],
      "metadata": {
        "id": "analyze_metrics_cnn"
      },
      "outputs": [],
      "id": "analyze_metrics_cnn",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Relevant Documentation:**\n",
        "* **Confusion Matrix:** A table that summarizes the performance of a classification model. Each row represents the instances in an actual class, while each column represents the instances in a predicted class. It helps visualize the types of errors made by the classifier (e.g., false positives, false negatives).\n",
        "    [Scikit-learn Confusion Matrix Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
        "    * **Sample Syntax:** `confusion_matrix(y_true, y_pred)`\n",
        "\n",
        "* **Classification Report:** Provides a more detailed breakdown of performance per class, including:\n",
        "    * **Precision:** The ability of the classifier not to label as positive a sample that is negative. (True Positives / (True Positives + False Positives))\n",
        "    * **Recall:** The ability of the classifier to find all the positive samples. (True Positives / (True Positives + False Negatives))\n",
        "    * **F1-Score:** The harmonic mean of precision and recall. A good balance between precision and recall.\n",
        "    * **Support:** The number of actual occurrences of the class in the specified dataset.\n",
        "    [Scikit-learn Classification Report Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
        "    * **Sample Syntax:** `classification_report(y_true, y_pred, target_names=['class_0', 'class_1'])`\n",
        "\n",
        "Examining the confusion matrix and classification report will help identify which classes your model performs well on and which it struggles with. For example, high false positives for one class and high false negatives for another might indicate confusion between those specific categories (e.g., 'cat' and 'dog' in CIFAR-10).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "PNQpfYC0Vx0-"
      },
      "id": "PNQpfYC0Vx0-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge & Extension Activities (If Time Permits)\n",
        "\n",
        "* **Data Augmentation:** Implement basic data augmentation (e.g., rotation, shifting, zooming) using `ImageDataGenerator` from `tf.keras.preprocessing.image` to improve generalization.\n",
        "* **Deeper Network:** Create a CNN with more `Conv2D` and `MaxPooling2D` layers. Be mindful of vanishing gradients or overfitting.\n",
        "* **Different Datasets:** Try classifying `fashion_mnist` (images of clothing).\n",
        "* **Callbacks:** Add Keras Callbacks like `EarlyStopping` to stop training when validation performance plateaus, or `ModelCheckpoint` to save the best model during training.\n",
        "* **Learning Rate Schedule:** Experiment with different learning rate schedules (e.g., reducing learning rate on plateau).\n",
        "* **Visualize Feature Maps:** Try to visualize the output of intermediate `Conv2D` layers to understand what features the CNN is learning."
      ],
      "metadata": {
        "id": "Bymf482yVx0-"
      },
      "id": "Bymf482yVx0-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "wddBlzceVx0-"
      },
      "id": "wddBlzceVx0-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deliverables:\n",
        "\n",
        "Students should submit their Jupyter Notebook containing all the code, outputs, and answers to the discussion questions."
      ],
      "metadata": {
        "id": "UCk3IDCoVx0-"
      },
      "id": "UCk3IDCoVx0-"
    }
  ]
}